{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Unsupervised learning on Weblogs v2\n\n> This Notebook is part of a study on applied machine learning for quick incident response, so please cite the \"Taking advantage of unsupervised learning in incident response\" article published in IWSSS 2020 proceedings -- \"2020 8th International Workshop on Systems Safety & Security (IWSSS)\" and \"Machine Learning Approach to Quick Incident Response\" article published in COMM2020 proceedings -- \"2020 13th International Conference on Communications (COMM)\".\n\n## 0. Intro\n\n### Creating a dataset from unseen before weblogs \n\nThe initial tests were conducted on weblogs that had reported incidents, to test the applicability of unsupervised learning techniques. \nOne of the characteristics of incident collected web access logs is their randomness. The events would be different from case to case and would contain seen before attack patterns, and more often than not, unseen ones. Considering this fact, the development of a rule-based tool would be extremely complicated, and could also miss relevant data. \nEmploying machine learning methods could result in improved results on new unseen data, compared to standard incident response tools and techniques.\nNevertheless, the extrapolated dataset will not respect best practice norms like:\nunique records for the training and testing, so that frequency will not influence the performance of the model;\nproperly labeled data;\nan equal number of records to represent each class in the observed space;\nstandard configuration and network architecture so that the result can be duplicated. \nUnsupervised learning could represent the answer, but as seen in earlier attempts, clustering on weblogs extracted features is not that easy. \nFor this part of this study, we used publicly available web access logs from the following sources: [Try Google query inurl:access.log filetype:log]\n- http://www.almhuette-raith.at/apache-log/access.log\n- https://www.todaynewsportal.com/access.log\n\nFeatures to look after:\n-    unusual_hours;\n-    has_bad_rep;\n-    shannon_entropy;      #new\n-    has_bad_string\n-    method;\n-    version;\n-    status;\n-    log_len_uri; \n-    log_bytes;\n-    scripting_useragent;\n-    label;                #Binary 1=Suspicious and 0=Safe\n-    id.                   #new"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/10k-idlabel/_dataset_web_10K_id_2_.csv\")\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"id\"],axis=1,inplace=True)    # dropped\n\ndf.tail()   # last 5 rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation of the dataset\n\nUsing cross-validation with ten folds method, we evaluated the efficiency of different machine learning algorithms on the resulting dataset.\nTo provide us with a quick start, we conducted the experiments with default parameters in Weka 3.8.4.\n\nAlgorithm | Precision |    MAE     | Obs.\n---|---|---|---\nZeroR|50.15 %|0.50|baseline\nOneR|96.91 %|0.03|used just shannon_entropy to make the prediction\nNaiveBayes|71.29 %|0.30|\nSVM|74.40 %|0.26|    \nJ48|99.18 %|0.01|\nRandomForest|99.37 %|0.01|most accurate on extracted features"},{"metadata":{},"cell_type":"markdown","source":"### Exploratory data analysis (EDA)\n\nEDA is an approach to dataset analysis in which the data is summarized using its main characteristics, often in visual form. We observe that the suspicious events are not easily separable from the safe ones, highlighted by the two different colors corresponding to the safe and suspicious labels."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.pairplot(data=df,hue=\"label\",palette=\"Set2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib#.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d, Axes3D \n\nfig = plt.figure(figsize=(10, 10))\n#fig = plt.figure()\n\nax = Axes3D(fig)\ncolors = ['red','green']\n'''\nshannon_entropy\nlog_bytes\nscripting_useragent\n'''\nxs = df['status']\nys = df['log_len_uri']\nzs = df['log_bytes']\n#mapping = {'safe': 0, 'suspicious': 1}\nlabel = df['label']#.replace(mapping)\nax.scatter(xs, ys, zs, c=label, cmap=matplotlib.colors.ListedColormap(colors), edgecolors='w')\n\nax.set_xlabel('status')\nax.set_ylabel('log_len_uri')\nax.set_zlabel('log_bytes')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfeatures = ['unusual_hours','has_bad_rep','shannon_entropy','method','version','status','log_len_uri','log_bytes','scripting_useragent']\n# Separating out the features\nx = df.loc[:, features].values\n# Separating out the target\n#df['label'].replace(0, 'Safe',inplace=True)\n#df['label'].replace(1, 'Suspicious',inplace=True)\ny = df.loc[:,['label']].values\n# Standardizing the features\nx = StandardScaler().fit_transform(x)\n\npca = PCA(n_components=3)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\nfinalDf = pd.concat([principalDf, df[['label']]], axis = 1)\n\nfig = plt.figure(figsize=(10, 10))\nax = Axes3D(fig)\ncolors = ['r', 'g', 'b']\n\nax.set_xlabel('principal component 1', fontsize = 15)\nax.set_ylabel('principal component 2', fontsize = 15)\nax.set_zlabel('principal component 3', fontsize = 15)\n\nax.set_title('3 component PCA', fontsize = 20)\n\ntargets = [0, 1]\n\nfor target, color in zip(targets,colors):\n    indicesToKeep = finalDf['label'] == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n               , finalDf.loc[indicesToKeep, 'principal component 2']\n               , finalDf.loc[indicesToKeep, 'principal component 3']\n               , c = color\n               , s = 50)\n\nax.legend(targets)\nax.grid()\nplt.show()\n\n# Import dependencies\nimport plotly\nimport plotly.graph_objs as go\n\n# Configure Plotly to be rendered inline in the notebook.\nplotly.offline.init_notebook_mode()\n\n# Configure the trace.\nfinalDf['label'].replace(0, 'Safe',inplace=True)\nfinalDf['label'].replace(1, 'Suspicious',inplace=True)\n\nsafe=finalDf.loc[finalDf['label'] == 'Safe']\nsuspicious=finalDf.loc[finalDf['label'] == 'Suspicious']\n\nfinalDf['label'].replace(0, 'Safe',inplace=True)\nfinalDf['label'].replace(1, 'Suspicious',inplace=True)\n\n\ntrace1 = go.Scatter3d(\n    x=safe['principal component 1'],\n    y=safe['principal component 2'],\n    z=safe['principal component 3'],\n    mode='markers',\n    name = \"Safe\",\n    marker=dict(\n        size=12,\n        color='rgba(66, 135, 245, 0.8)'\n    ),\n    text= finalDf.label\n)\n\ntrace2 = go.Scatter3d(\n    x=suspicious['principal component 1'],\n    y=suspicious['principal component 2'],\n    z=suspicious['principal component 3'],\n    mode='markers',\n    name = \"Suspicious\",\n    marker=dict(\n        size=12,\n        color = 'rgba(235, 64, 52, 0.8)'\n    ),\n    text= finalDf.label\n)\n\n# Configure the layout.\nlayout = go.Layout(\n    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n)\n\ndata = [trace1, trace2]\n\nplot_figure = go.Figure(data=data, layout=layout)\n\n# Render the plot.\nplotly.offline.iplot(plot_figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Testing K-Means Clustering \n\n### Adjusting the dataset for unsupervised learning\nFor unsupervised learning, we do not need the labels for the feature vectors. We are not dropping the scripting_useragent column, even though the value is always 0 since, in the new data, we could have other values. This characteristic can be quickly dropped in the code below as needed. We also encode the labels as 0 for safe items and 1 for suspicious."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import entropy \nfrom pandas.core.algorithms import value_counts\n\n#X = df.drop(['label'], axis=1)\n#mapping = {'safe': 0, 'suspicious': 1}\n#y = df['label'].replace(mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the ideal number of clusters\n\nIdeally, the dataset should be grouped around two cluster centers and should be easily separated into the two categories, safe and suspicious. If we use methods for ideal cluster number determination, like the ones presented below, we observe that the theoretical number of clusters is way beyond two.\nTo demonstrate, we use SciKit-Learn implementation with most of the parameters as default. Even though we already know that we should differentiate two clusters, it is an outstanding practice to check the ideal amount with algorithms like: [1,2,3,4]\n- The elbow method looks at the total With-in-Sum-of-Squares (WSS) as a function of the number of clusters. We should choose a number of clusters so that the addition of one more will not significantly improve the total WSS;\n- The gap statistic method compares the total within intra-cluster variation for different kâ€™s with their expected values under the null reference distribution of the data. The optimal k will be the value that maximizes the gap statistic (e.g., that yields the most significant gap statistic). (R. Tibshirani, G. Walther, and T. Hastie, Standford University, 2001);\n- The Silhouette method computes the average silhouette of observations for different values of k. The optimal k maximizes the average silhouette (Kaufman and Rousseeuw 1990)."},{"metadata":{"trusted":true},"cell_type":"code","source":"##Calculation \n%matplotlib inline\nimport time\nimport hashlib\nimport scipy\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.metrics import silhouette_score\n\ndef optimalK(data, nrefs=3, maxClusters=20):\n    \"\"\"\n    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n    Params:\n        data: ndarry of shape (n_samples, n_features)\n        nrefs: number of sample reference datasets to create\n        maxClusters: Maximum number of clusters to test for\n    Returns: (gaps, optimalK)\n    \"\"\"\n    gaps = np.zeros((len(range(1, maxClusters)),))\n    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n    for gap_index, k in enumerate(range(1, maxClusters)):\n\n        # Holder for reference dispersion results\n        refDisps = np.zeros(nrefs)\n\n        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n        for i in range(nrefs):\n            \n            # Create new random reference set\n            randomReference = np.random.random_sample(size=data.shape)\n            \n            # Fit to it\n            km = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n            km.fit(randomReference)\n            \n            refDisp = km.inertia_\n            refDisps[i] = refDisp\n\n        # Fit cluster to original data and create dispersion\n        km = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n        km.fit(data)\n        \n        origDisp = km.inertia_\n\n        # Calculate gap statistic\n        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n\n        # Assign this loop's gap statistic to gaps\n        gaps[gap_index] = gap\n        \n        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n\n    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n\nsil = []\nkmax = 20\nwcss = []\n\nfor k in range(2, kmax+1):\n  kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0).fit(X)\n  labels = kmeans.labels_\n  sil.append(silhouette_score(X, labels, metric = 'euclidean'))\n\nfor k in range(1,kmax):\n    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    \nk, gapdf = optimalK(X, nrefs=5)\n#print('Optimal k (GAP): ', k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Visualisation \nplt.figure(figsize=(20,10))\nplt.suptitle('Ideal K',fontsize=20)\n\nplt.subplot(1,2,1)\nplt.plot(range(1,20),wcss,\"-o\")\nplt.grid(True)\nplt.ylabel('WCSS',fontsize=35)\n'''\nplt.subplot(1,3,2)\nplt.plot(gapdf.clusterCount, gapdf.gap, linewidth=3)\nplt.grid(True)\nplt.scatter(gapdf[gapdf.clusterCount == k].clusterCount, gapdf[gapdf.clusterCount == k].gap, s=250, c='r')\nplt.xlabel('Cluster Count',fontsize=20)\nplt.ylabel('Gap Value',fontsize=35)\n\nplt.subplot(1,3,3)\nplt.plot(range(1,20),sil)\nplt.grid(True)\nplt.ylabel(\"Silhouette Score\",fontsize=35)\n'''\nx_ticks=['x tick 1','x tick 2','x tick 3']\nax.set_xticklabels(x_ticks, rotation=0, fontsize=3)\n\nplt.show()\n\nimport pandas as pd\nimport numpy as np\n\nX = df.drop(['label'], axis=1)\n#mapping = {'safe': 0, 'suspicious': 1}\ny = df['label']#.replace(mapping)\n\n#data = df\n#X = data.iloc[:,0:20]  #independent columns\n#y = data.iloc[:,-1]    #target column i.e price range\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As seen above, the results obtained from the elbow and gap methods are not promising, since they return very high values for k. Nevertheless, the third evaluation is encouraging since the Silhouette Score is at its maximum when k is 3. To summarise, none of the tests gave us the desired k = 2. This result is an expected one since there are situations when the extracted features have very close values for both safe and suspicious events. The next step should be to enhance somehow the dataset so that the clusters could be more separable.**"},{"metadata":{},"cell_type":"markdown","source":"## 2. Dataset enrichment\n\nAs in hybrid classifiers, we intend to use additional supervised algorithms to improve the overall results.\nFirst, we tried Linear Regression and evaluated the dataset based on the following primary metrics:\n- Mean Absolute Error (MAE) â€“ the average error;\n- Mean Squared Error (MSE) â€“ more significant errors are punished;\n- Root Mean Squared Error (RMSE) â€“ it is recommended that it should be used as the primary metric to interpret your model."},{"metadata":{"trusted":true},"cell_type":"code","source":"##Linear Regression\nimport pandas as pd  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nimport seaborn as seabornInstance\nfrom sklearn.metrics import precision_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n%matplotlib inline\nfrom sklearn import metrics\nimport joblib\n\nfeatures = df.drop(['label'], axis=1)\n\ntrain = df.sample(n=900, replace=True, random_state=1)\ntest = df.drop(train.index)\n\nX_train = train.drop(['label'], axis=1)\nmapping = {'safe': 0, 'suspicious': 1}\ny_train = train['label'].replace(mapping)\n\nX_test = test.drop(['label'], axis=1)\nmapping = {'safe': 0, 'suspicious': 1}\ny_test = test['label'].replace(mapping)\n\nregressor = LinearRegression()  \nregressor.fit(X_train, y_train) #training the algorithm\n\n#To retrieve the intercept:\nprint('Intercept: %.8f' % regressor.intercept_)\n#For retrieving the slope:\n#print(regressor.coef_)\n\n# save the model to disk\nfilename = 'LR.model'\njoblib.dump(regressor, filename)\n\ny_pred = regressor.predict(X_test).round()\n\ny_test = np.array(list(y_test))\ny_pred = np.array(y_pred)\n\ncount=0\n\nfor i in range(len(y_test)):\n    if y_test.flatten()[i] !=  round(y_pred.flatten()[i]):\n        count+=1\n     \nprecision = precision_score(y_test, y_pred, average='micro')\nprint('Precision: %.2f' % float(precision*100), \"%\")\n\n#print(count)\n#print(len(y_test))\n\n#dataset2 = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n#dataset2\n\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\ncoeffecients = pd.DataFrame(regressor.coef_,X_test.columns)\ncoeffecients.columns = ['Coeffecient']\n#coeffecients","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The precision on the observed known data has improved significantly. Let us try adding one more feature based on the original ones by employing the Multi-layer Perceptron algorithm.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"##Multi-layer Perceptron \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import precision_score\nimport joblib\n\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n                    hidden_layer_sizes=(5, 2), random_state=1)\n\nclf.fit(X_train, y_train)\n#print([coef.shape for coef in clf.coefs_])\n#print(clf.coefs_)\n\ny_pred = clf.predict(X_test)\n\nprecision = precision_score(y_test, y_pred, average='micro')\nprint('Precision: %.2f' % float(precision*100), \"%\")\n\nfeatures[\"mlp_pred\"] = (clf.predict(features[[\"unusual_hours\", \n                                             \"has_bad_rep\",\n                                             \"has_bad_string\", \n                                             \"method\", \n                                             \"version\", \n                                             \"status\", \n                                             \"log_len_uri\", \n                                             \"log_bytes\", \n                                             \"scripting_useragent\"]]))\n\n# save the model to disk\nfilename = 'MLP.model'\njoblib.dump(clf, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features[\"lr_pred\"] = (0.13688273 * df[\"unusual_hours\"] \n                     + 0.03655747 * df[\"has_bad_rep\"] \n                     + 0.04017277 * df[\"has_bad_string\"] \n                     - 0.05029479 * df[\"method\"] \n                     + 0.34400104 * df[\"version\"] \n                     + 0.20885592 * df[\"status\"] \n                     + 0.41214625 * df[\"log_len_uri\"]\n                     - 0.00410462 * df[\"log_bytes\"]\n                     + 0.00000000 * df[\"scripting_useragent\"]\n                     - 0.45363860)\n\ndf[\"lr_pred\"] = (0.13688273 * df[\"unusual_hours\"] \n                     + 0.03655747 * df[\"has_bad_rep\"] \n                     + 0.04017277 * df[\"has_bad_string\"] \n                     - 0.05029479 * df[\"method\"] \n                     + 0.34400104 * df[\"version\"] \n                     + 0.20885592 * df[\"status\"] \n                     + 0.41214625 * df[\"log_len_uri\"]\n                     - 0.00410462 * df[\"log_bytes\"]\n                     + 0.00000000 * df[\"scripting_useragent\"]\n                     - 0.45363860)\n\ndf[\"mlp_pred\"] = (clf.predict(df[[\"unusual_hours\", \n                                    \"has_bad_rep\",\n                                    \"has_bad_string\", \n                                    \"method\", \n                                    \"version\", \n                                    \"status\", \n                                    \"log_len_uri\", \n                                    \"log_bytes\", \n                                    \"scripting_useragent\"]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Testing unsupervised learning on the new dataset\n\nWe have plotted the graphical representation based on the most significant features (log_bytes and has_bad_strings) for k between 1 and 4, as suggested by the CfsSubsetEval algorithm [5]."},{"metadata":{"trusted":true,"_uuid":"077da0f8ce81a668937bb6c09902ec401834fe46"},"cell_type":"code","source":"plt.figure(figsize=(24,4))\n\nplt.suptitle(\"K Means Clustering\",fontsize=20)\n\nplt.subplot(1,5,1)\nplt.title(\"K = 1\",fontsize=16)\nplt.xlabel(\"log_len_uri\")\nplt.ylabel(\"has_bad_strings\")\nplt.scatter(features.log_len_uri,features.has_bad_string)\n\n\nplt.subplot(1,5,2)\nplt.title(\"K = 2\",fontsize=16)\nplt.xlabel(\"log_len_uri\")\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\nfeatures[\"labels\"] = kmeans.fit_predict(features)\nplt.scatter(features.log_len_uri[features.labels == 0],features.has_bad_string[features.labels == 0])\nplt.scatter(features.log_len_uri[features.labels == 1],features.has_bad_string[features.labels == 1])\n\n# I drop labels since we only want to use features.\nfeatures.drop([\"labels\"],axis=1,inplace=True)\n\nplt.subplot(1,5,4)\nplt.title(\"K = 3\",fontsize=16)\nplt.xlabel(\"log_len_uri\")\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\nfeatures[\"labels\"] = kmeans.fit_predict(features)\nplt.scatter(features.log_len_uri[features.labels == 0],features.has_bad_string[features.labels == 0])\nplt.scatter(features.log_len_uri[features.labels == 1],features.has_bad_string[features.labels == 1])\nplt.scatter(features.log_len_uri[features.labels == 2],features.has_bad_string[features.labels == 2])\n\n# I drop labels since we only want to use features.\nfeatures.drop([\"labels\"],axis=1,inplace=True)\n\nplt.subplot(1,5,3)\nplt.title(\"K = 4\",fontsize=16)\nplt.xlabel(\"log_len_uri\")\nkmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\nfeatures[\"labels\"] = kmeans.fit_predict(features)\nplt.scatter(features.log_len_uri[features.labels == 0],features.has_bad_string[features.labels == 0])\nplt.scatter(features.log_len_uri[features.labels == 1],features.has_bad_string[features.labels == 1])\nplt.scatter(features.log_len_uri[features.labels == 2],features.has_bad_string[features.labels == 2])\nplt.scatter(features.log_len_uri[features.labels == 3],features.has_bad_string[features.labels == 3])\n\n# I drop labels since we only want to use features.\nfeatures.drop([\"labels\"],axis=1,inplace=True)\n\nplt.subplot(1,5,5)\nplt.title(\"Original Labels\",fontsize=16)\nplt.xlabel(\"log_len_uri\")\nplt.scatter(df.log_len_uri[df.label == \"suspicious\"],df.has_bad_string[df.label == \"suspicious\"])\nplt.scatter(df.log_len_uri[df.label == \"safe\"],df.has_bad_string[df.label == \"safe\"])\n\nplt.subplots_adjust(top=0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We observe that for k = 2, the graphical representation is quite similar to the original labeling, but we still do not observe separable clusters.**\n\n**Let us also try the hierarchical clustering method. We are looking for the longest vertical line without any perpendicular matching lines (euclidian distances). We observed three significant groups in the graphical representation of the hierarchical clustering method on our data, so the ideal number of labels would be three.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import dendrogram, linkage\n\nmerg = linkage(features,method=\"ward\")\n\nplt.figure(figsize=(18,6))\ndendrogram(merg, leaf_rotation=90)\nplt.xlabel(\"data points\")\nplt.ylabel(\"euclidian distance\")\n\nplt.suptitle(\"DENDROGRAM\",fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This result is a more realistic depiction of our data since the dataset contains elements with almost identical feature vectors from distinct classes.**"},{"metadata":{"trusted":true,"_uuid":"d33441d87d33b3867448fa4e32ba1dfd6bfdd6f8"},"cell_type":"markdown","source":"## 4. Evaluation and comparison of the results"},{"metadata":{"trusted":true,"_uuid":"4826b560dfc8a1ac45a121fcc08db40978c39b35","scrolled":false},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\nfeatures[\"labels\"] = kmeans.fit_predict(features[['lr_pred', 'mlp_pred']])\n\n# cross tabulation table for kmeans\ndf1 = pd.DataFrame({'pred':features['labels'] ,\"label\":df['label'] })\nct1 = pd.crosstab(df1['label'],df1['pred'])\n\n\n# hierarchy\nhc_cluster = AgglomerativeClustering(n_clusters=2)\nhc_predict = hc_cluster.fit_predict(features[['lr_pred', 'mlp_pred']])\n\n# cross tabulation table for Hierarchy\ndf2 = pd.DataFrame({'labels':hc_predict,\"label\":df['label']})\nct2 = pd.crosstab(df2['labels'],df2['label'])\n\n\nplt.figure(figsize=(24,8))\nplt.suptitle(\"CROSS TABULATIONS\",fontsize=18)\nplt.subplot(1,2,1)\nplt.title(\"KMeans\")\nsns.heatmap(ct1,annot=True,cbar=False,cmap=\"Blues\")\n\nplt.subplot(1,2,2)\nplt.title(\"Hierarchy\")\nsns.heatmap(ct2,annot=True,cbar=False,cmap=\"Blues\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The routine below will evaluate the 10k extracted dataset, from the original web access log. You can use the extractor script to <extract> features from the rest of the web logs."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport joblib\n\nd10k = pd.read_csv(\"../input/10k-access/dataset_web_10K.csv\", delimiter=',')\n\n# load the models from disk\nMLP_model = joblib.load('MLP.model')\nLR_model = joblib.load('LR.model')\n\n#print(d10k[['scripting_useragent']])\nd10k[\"mlp_pred\"] = (MLP_model.predict(d10k[[\"unusual_hours\", \n                                                 \"has_bad_rep\",\n                                                 \"has_bad_string\", \n                                                 \"method\", \n                                                 \"version\", \n                                                 \"status\", \n                                                 \"log_len_uri\", \n                                                 \"log_bytes\", \n                                                 \"scripting_useragent\"]]))\n\nd10k[\"lr_pred\"] = (LR_model.predict(d10k[[\"unusual_hours\", \n                                                 \"has_bad_rep\",\n                                                 \"has_bad_string\", \n                                                 \"method\", \n                                                 \"version\", \n                                                 \"status\", \n                                                 \"log_len_uri\", \n                                                 \"log_bytes\", \n                                                 \"scripting_useragent\"]]))\n\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\nd10k[\"labels\"] = kmeans.fit_predict(d10k[['lr_pred', 'mlp_pred']])\n\nplt.figure(figsize=(15,10))\nplt.title(\"Unknown items\", fontsize=18)\nplt.grid(True)\nplt.scatter(d10k.log_len_uri[d10k.labels == 0],d10k.lr_pred[d10k.labels == 0])\nplt.scatter(d10k.log_len_uri[d10k.labels == 1],d10k.lr_pred[d10k.labels == 1])\nplt.xlabel(\"log_len_uri\",fontsize=14)\nplt.ylabel(\"lr_pred\",fontsize=14)\nplt.tight_layout()\nplt.show()\n\nd10k.to_csv (r'export_labeled_df.csv', index = False, header=True)\nprint(\"Saved csv!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib#.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d, Axes3D \n\nfig = plt.figure(figsize=(10, 10))\n#fig = plt.figure()\n\nax = Axes3D(fig)\ncolors = ['red','green']\n\nxs = d10k['status']\nys = d10k['log_len_uri']\nzs = d10k['log_bytes']\nlabel = d10k.labels\nax.scatter(xs, ys, zs, c=label, cmap=matplotlib.colors.ListedColormap(colors), edgecolors='w')\n\nax.set_xlabel('status')\nax.set_ylabel('log_len_uri')\nax.set_zlabel('log_bytes')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f8d36d18a675a10f7d7e51f1ef44a64a097a1d6"},"cell_type":"markdown","source":"# Conclusion\n\n### The features extracted from the weblogs are not enough for clustering, so we need to implement supervised learning algorithms to extract data form labeled entries. \n\n### As future work, the analysis process applied to requests can be improved, switching from a string match method to a principal component analysis (PCA) and entropy calculation."},{"metadata":{},"cell_type":"markdown","source":"# Sources\n\n[1] Satsawat Natakarnkitkul, Get the Optimal K in K-Means Clustering, https://medium.com/towards-artificial-intelligence/get-the-optimal-k-in-k-means-clustering-d45b5b8a4315\n\n[2] Robert Tibshirani, Guenther Walther and Trevor Hastie, Estimating the number of clusters in a data set via the gap statistic, https://statweb.stanford.edu/~gwalther/gap\n\n[3] https://www.programcreek.com/python/example/97803/tqdm.tqdm_notebook\n\n[4] Khyati Mahendru, How to Determine the Optimal K for K-Means?, https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb\n\n[5] M. A. Hall, Correlation-based Feature Subset Selection for Machine Learning. Hamilton, New Zealand (1998).\n\n[6] Efe Ergun, Unsupervised Learning on Iris, https://www.kaggle.com/efeergun96/unsupervised-learning-on-iris"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}